{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mHDxn9VHjxKn"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "3x19oys5j89H"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hFDUpbtvv_3u"
   },
   "source": [
    "# Saving and Serializing Models with TensorFlow Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V94_3U2k9rWV"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/beta/guide/keras/saving_and_serializing\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/r2/guide/keras/saving_and_serializing.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/r2/guide/keras/saving_and_serializing.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/r2/guide/keras/saving_and_serializing.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZwiVWAQc9tk7"
   },
   "source": [
    "The first part of this guide covers saving and serialization for Sequential models and models built using the Functional API and for Sequential models. The saving and serialization APIs are the exact same for both of these types of models.\n",
    "\n",
    "Saving for custom subclasses of `Model` is covered in the section \"Saving Subclassed Models\". The APIs in this case are slightly different than for Sequential or Functional models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uqSgPMHguAAs"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bx5w4U5muDAo"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.keras.backend.clear_session()  # For easy reset of notebook state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wwCxkE6RyyPy"
   },
   "source": [
    "## Part I: Saving Sequential models or Functional models\n",
    "\n",
    "Let's consider the following model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ILmySACTvSA9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"3_layer_mlp\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "digits (InputLayer)          [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 55,050\n",
      "Trainable params: 55,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = keras.Input(shape=(784,), name='digits')\n",
    "x = layers.Dense(64, activation='relu', name='dense_1')(inputs)\n",
    "x = layers.Dense(64, activation='relu', name='dense_2')(x)\n",
    "outputs = layers.Dense(10, activation='softmax', name='predictions')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name='3_layer_mlp')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xPRqbd0yw8hY"
   },
   "source": [
    "Optionally, let's train this model, just so it has weight values to save, as well as an an optimizer state.\n",
    "Of course, you can save models you've never trained, too, but obviously that's less interesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gCygTeGQw74g"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0813 01:45:36.125004 140478333425408 deprecation.py:323] From /tmpfs/src/tf_docs_env/lib/python3.5/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "60000/60000 [==============================] - 3s 48us/sample - loss: 0.3097\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
    "x_test = x_test.reshape(10000, 784).astype('float32') / 255\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.RMSprop())\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=64,\n",
    "                    epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "htnmbhz-iOwh"
   },
   "outputs": [],
   "source": [
    "# Save predictions for future checks\n",
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "opP1KROHwWwd"
   },
   "source": [
    "\n",
    "### Whole-model saving\n",
    "\n",
    "You can save a model built with the Functional API into a single file. You can later recreate the same model from this file, even if you no longer have access to the code that created the model.\n",
    "\n",
    "This file includes:\n",
    "\n",
    "- The model's architecture\n",
    "- The model's weight values (which were learned during training)\n",
    "- The model's training config (what you passed to `compile`), if any\n",
    "- The optimizer and its state, if any (this enables you to restart training where you left off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HqHvq6Igw3wx"
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('path_to_my_model.h5')\n",
    "\n",
    "# Recreate the exact same model purely from the file\n",
    "new_model = keras.models.load_model('path_to_my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mmIcF6UOItJE"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Check that the state is preserved\n",
    "new_predictions = new_model.predict(x_test)\n",
    "np.testing.assert_allclose(predictions, new_predictions, rtol=1e-6, atol=1e-6)\n",
    "\n",
    "# Note that the optimizer state is preserved as well:\n",
    "# you can resume training where you left off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-WEPW3n8ICyz"
   },
   "source": [
    "### Export to SavedModel\n",
    "\n",
    "You can also export a whole model to the TensorFlow `SavedModel` format. `SavedModel` is a standalone serialization format for Tensorflow objects, supported by TensorFlow serving as well as TensorFlow implementations other than Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cKASRTKCU5nv"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0813 01:45:41.360875 140478333425408 deprecation.py:323] From /tmpfs/src/tf_docs_env/lib/python3.5/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:253: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "W0813 01:45:41.362421 140478333425408 export_utils.py:182] Export includes no default signature!\n",
      "W0813 01:45:41.611759 140478333425408 export_utils.py:182] Export includes no default signature!\n"
     ]
    }
   ],
   "source": [
    "# Export the model to a SavedModel\n",
    "keras.experimental.export_saved_model(model, 'path_to_saved_model')\n",
    "\n",
    "# Recreate the exact same model\n",
    "new_model = keras.experimental.load_from_saved_model('path_to_saved_model')\n",
    "\n",
    "# Check that the state is preserved\n",
    "new_predictions = new_model.predict(x_test)\n",
    "np.testing.assert_allclose(predictions, new_predictions, rtol=1e-6, atol=1e-6)\n",
    "\n",
    "# Note that the optimizer state is preserved as well:\n",
    "# you can resume training where you left off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4AWgwkKWIhfj"
   },
   "source": [
    "The `SavedModel` files that were created contain:\n",
    "\n",
    "- A TensorFlow checkpoint containing the model weights.\n",
    "- A `SavedModel` proto containing the underlying Tensorflow graph. Separate\n",
    "     graphs are saved for prediction (serving), train, and evaluation. If\n",
    "     the model wasn't compiled before, then only the inference graph\n",
    "     gets exported.\n",
    "- The model's architecture config, if available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GkY8XP_XxgMI"
   },
   "source": [
    "### Architecture-only saving\n",
    "\n",
    "Sometimes, you are only interested in the architecture of the model, and you don't need to save the weight values or the optimizer. In this case, you can retrieve the \"config\" of the model via the `get_config()` method. The config is a Python dict that enables you to recreate the same model -- initialized from scratch, without any of the information learned previously during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yQGGvo2Fw4o-"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0813 01:45:42.456218 140478333425408 util.py:244] Unresolved object in checkpoint: (root).optimizer.decay\n",
      "W0813 01:45:42.457242 140478333425408 util.py:244] Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "W0813 01:45:42.457919 140478333425408 util.py:244] Unresolved object in checkpoint: (root).optimizer.momentum\n",
      "W0813 01:45:42.458552 140478333425408 util.py:244] Unresolved object in checkpoint: (root).optimizer.rho\n",
      "W0813 01:45:42.459227 140478333425408 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-0.kernel\n",
      "W0813 01:45:42.459843 140478333425408 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-0.bias\n",
      "W0813 01:45:42.460608 140478333425408 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-1.kernel\n",
      "W0813 01:45:42.461344 140478333425408 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-1.bias\n",
      "W0813 01:45:42.462012 140478333425408 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-2.kernel\n",
      "W0813 01:45:42.462632 140478333425408 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-2.bias\n",
      "W0813 01:45:42.463326 140478333425408 util.py:252] A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n",
      "W0813 01:45:42.467581 140478333425408 util.py:244] Unresolved object in checkpoint: (root).optimizer\n",
      "W0813 01:45:42.468270 140478333425408 util.py:244] Unresolved object in checkpoint: (root).optimizer.iter\n",
      "W0813 01:45:42.468948 140478333425408 util.py:244] Unresolved object in checkpoint: (root).optimizer.decay\n",
      "W0813 01:45:42.469592 140478333425408 util.py:244] Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "W0813 01:45:42.470337 140478333425408 util.py:244] Unresolved object in checkpoint: (root).optimizer.momentum\n",
      "W0813 01:45:42.470990 140478333425408 util.py:244] Unresolved object in checkpoint: (root).optimizer.rho\n",
      "W0813 01:45:42.471621 140478333425408 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-0.kernel\n",
      "W0813 01:45:42.472242 140478333425408 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-0.bias\n",
      "W0813 01:45:42.472919 140478333425408 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-1.kernel\n",
      "W0813 01:45:42.473589 140478333425408 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-1.bias\n",
      "W0813 01:45:42.474272 140478333425408 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-2.kernel\n",
      "W0813 01:45:42.474914 140478333425408 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-2.bias\n",
      "W0813 01:45:42.475561 140478333425408 util.py:252] A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "config = model.get_config()\n",
    "reinitialized_model = keras.Model.from_config(config)\n",
    "\n",
    "# Note that the model state is not preserved! We only saved the architecture.\n",
    "new_predictions = reinitialized_model.predict(x_test)\n",
    "assert abs(np.sum(predictions - new_predictions)) > 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WsNBBvDgxsTS"
   },
   "source": [
    "You can alternatively use `to_json()` from `from_json()`, which uses a JSON string to store the config instead of a Python dict. This is useful to save the config to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5a0z7_6XxqWV"
   },
   "outputs": [],
   "source": [
    "json_config = model.to_json()\n",
    "reinitialized_model = keras.models.model_from_json(json_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SGC7R6IIxy0o"
   },
   "source": [
    "### Weights-only saving\n",
    "\n",
    "Sometimes, you are only interested in the state of the model -- its weights values -- and not in the architecture. In this case, you can retrieve the weights values as a list of Numpy arrays via `get_weights()`, and set the state of the model via `set_weights`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B8tHwEvkxw5E"
   },
   "outputs": [],
   "source": [
    "weights = model.get_weights()  # Retrieves the state of the model.\n",
    "model.set_weights(weights)  # Sets the state of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ydwtw-u2x7xC"
   },
   "source": [
    "You can combine `get_config()`/`from_config()` and `get_weights()`/`set_weights()` to recreate your model in the same state. However, unlike `model.save()`, this will not include the training config and the optimizer. You would have to call `compile()` again before using the model for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LWVtuxtrx5lb"
   },
   "outputs": [],
   "source": [
    "config = model.get_config()\n",
    "weights = model.get_weights()\n",
    "\n",
    "new_model = keras.Model.from_config(config)\n",
    "new_model.set_weights(weights)\n",
    "\n",
    "# Check that the state is preserved\n",
    "new_predictions = new_model.predict(x_test)\n",
    "np.testing.assert_allclose(predictions, new_predictions, rtol=1e-6, atol=1e-6)\n",
    "\n",
    "# Note that the optimizer was not preserved,\n",
    "# so the model should be compiled anew before training\n",
    "# (and the optimizer will start from a blank state)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "prk0GzwCyIYy"
   },
   "source": [
    "The save-to-disk alternative to `get_weights()` and `set_weights(weights)`\n",
    "is `save_weights(fpath)` and `load_weights(fpath)`.\n",
    "\n",
    "Here's an example that saves to disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2irLnOUbyHlI"
   },
   "outputs": [],
   "source": [
    "# Save JSON config to disk\n",
    "json_config = model.to_json()\n",
    "with open('model_config.json', 'w') as json_file:\n",
    "    json_file.write(json_config)\n",
    "# Save weights to disk\n",
    "model.save_weights('path_to_my_weights.h5')\n",
    "\n",
    "# Reload the model from the 2 files we saved\n",
    "with open('model_config.json') as json_file:\n",
    "    json_config = json_file.read()\n",
    "new_model = keras.models.model_from_json(json_config)\n",
    "new_model.load_weights('path_to_my_weights.h5')\n",
    "\n",
    "# Check that the state is preserved\n",
    "new_predictions = new_model.predict(x_test)\n",
    "np.testing.assert_allclose(predictions, new_predictions, rtol=1e-6, atol=1e-6)\n",
    "\n",
    "# Note that the optimizer was not preserved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KBxcFAPHyYi5"
   },
   "source": [
    "But remember that the simplest, recommended way is just this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DE4b3ndNyQh3"
   },
   "outputs": [],
   "source": [
    "model.save('path_to_my_model.h5')\n",
    "del model\n",
    "model = keras.models.load_model('path_to_my_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yKikmbdC3O_i"
   },
   "source": [
    "### Weights-only saving in SavedModel format\n",
    "\n",
    "Note that `save_weights` can create files either in the Keras HDF5 format,\n",
    "or in the TensorFlow SavedModel format. The format is infered from the file extension\n",
    "you provide: if it is \".h5\" or \".keras\", the framework uses the Keras HDF5 format. Anything\n",
    "else defaults to SavedModel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0pYKb6LV3h2l"
   },
   "outputs": [],
   "source": [
    "model.save_weights('path_to_my_tf_savedmodel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZFwKv6JC3kyu"
   },
   "source": [
    "For total explicitness, the format can be explicitly passed via the `save_format` argument, which can take the value \"tf\" or \"h5\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oN9vOaWU34lA"
   },
   "outputs": [],
   "source": [
    "model.save_weights('path_to_my_tf_savedmodel', save_format='tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xXgtNRCSyuIW"
   },
   "source": [
    "## Saving Subclassed Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mJqOn0snzCRy"
   },
   "source": [
    "Sequential models and Functional models are datastructures that represent a DAG of layers. As such,\n",
    "they can be safely serialized and deserialized.\n",
    "\n",
    "A subclassed model differs in that it's not a datastructure, it's a piece of code. The architecture of the model\n",
    "is defined via the body of the `call` method. This means that the architecture of the model cannot be safely serialized. To load a model, you'll need to have access to the code that created it (the code of the model subclass). Alternatively, you could be serializing this code as bytecode (e.g. via pickling), but that's unsafe and generally not portable.\n",
    "\n",
    "For more information about these differences, see the article [\"What are Symbolic and Imperative APIs in TensorFlow 2.0?\"](https://medium.com/tensorflow/what-are-symbolic-and-imperative-apis-in-tensorflow-2-0-dfccecb01021)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pkwyu5dVz12P"
   },
   "source": [
    "Let's consider the following subclassed model, which follows the same structure as the model from the first section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Onp-8rGyeQG"
   },
   "outputs": [],
   "source": [
    "class ThreeLayerMLP(keras.Model):\n",
    "\n",
    "  def __init__(self, name=None):\n",
    "    super(ThreeLayerMLP, self).__init__(name=name)\n",
    "    self.dense_1 = layers.Dense(64, activation='relu', name='dense_1')\n",
    "    self.dense_2 = layers.Dense(64, activation='relu', name='dense_2')\n",
    "    self.pred_layer = layers.Dense(10, activation='softmax', name='predictions')\n",
    "\n",
    "  def call(self, inputs):\n",
    "    x = self.dense_1(inputs)\n",
    "    x = self.dense_2(x)\n",
    "    return self.pred_layer(x)\n",
    "\n",
    "def get_model():\n",
    "  return ThreeLayerMLP(name='3_layer_mlp')\n",
    "\n",
    "model = get_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wwT_YoKA0yQW"
   },
   "source": [
    "First of all, *a subclassed model that has never been used cannot be saved*.\n",
    "\n",
    "That's because a subclassed model needs to be called on some data in order to create its weights.\n",
    "\n",
    "Until the model has been called, it does not know the shape and dtype of the input data it should be\n",
    "expecting, and thus cannot create its weight variables. You may remember that in the Functional model from the first section, the shape and dtype of the inputs was specified in advance (via `keras.Input(...)`) -- that's why Functional models have a state as soon as they're instantiated.\n",
    "\n",
    "Let's train the model, so as to give it a state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xqP4kIFN0fTZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.3127\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
    "x_test = x_test.reshape(10000, 784).astype('float32') / 255\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.RMSprop())\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=64,\n",
    "                    epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rvGCpyX72HOC"
   },
   "source": [
    "The recommended way to save a subclassed model is to use `save_weights` to create a TensorFlow SavedModel checkpoint, which will contain the value of all variables associated with the model:\n",
    "- The layers' weights\n",
    "- The optimizer's state\n",
    "- Any variables associated with stateful model metrics (if any)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gMg87Tz01cxQ"
   },
   "outputs": [],
   "source": [
    "model.save_weights('path_to_my_weights', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KOKNBojtsl0F"
   },
   "outputs": [],
   "source": [
    "# Save predictions for future checks\n",
    "predictions = model.predict(x_test)\n",
    "# Also save the loss on the first batch\n",
    "# to later assert that the optimizer state was preserved\n",
    "first_batch_loss = model.train_on_batch(x_train[:64], y_train[:64])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h2PM_PL1SzPo"
   },
   "source": [
    "To restore your model, you will need access to the code that created the model object.\n",
    "\n",
    "Note that in order to restore the optimizer state and the state of any stateful  metric, you should\n",
    "compile the model (with the exact same arguments as before) and call it on some data before calling `load_weights`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OOSGiSkHTERy"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0813 01:45:48.777727 140478333425408 util.py:244] Unresolved object in checkpoint: (root).optimizer\n",
      "W0813 01:45:48.779095 140478333425408 util.py:244] Unresolved object in checkpoint: (root).optimizer.iter\n",
      "W0813 01:45:48.779940 140478333425408 util.py:244] Unresolved object in checkpoint: (root).optimizer.decay\n",
      "W0813 01:45:48.780753 140478333425408 util.py:244] Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "W0813 01:45:48.781521 140478333425408 util.py:244] Unresolved object in checkpoint: (root).optimizer.momentum\n",
      "W0813 01:45:48.782346 140478333425408 util.py:244] Unresolved object in checkpoint: (root).optimizer.rho\n",
      "W0813 01:45:48.783369 140478333425408 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-0.kernel\n",
      "W0813 01:45:48.784945 140478333425408 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-0.bias\n",
      "W0813 01:45:48.785531 140478333425408 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-1.kernel\n",
      "W0813 01:45:48.786112 140478333425408 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-1.bias\n",
      "W0813 01:45:48.786848 140478333425408 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-2.kernel\n",
      "W0813 01:45:48.788491 140478333425408 util.py:244] Unresolved object in checkpoint: (root).optimizer's state 'rms' for (root).layer_with_weights-2.bias\n",
      "W0813 01:45:48.789519 140478333425408 util.py:252] A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "# Recreate the model\n",
    "new_model = get_model()\n",
    "new_model.compile(loss='sparse_categorical_crossentropy',\n",
    "                  optimizer=keras.optimizers.RMSprop())\n",
    "\n",
    "# This initializes the variables used by the optimizers,\n",
    "# as well as any stateful metric variables\n",
    "new_model.train_on_batch(x_train[:1], y_train[:1])\n",
    "\n",
    "# Load the state of the old model\n",
    "new_model.load_weights('path_to_my_weights')\n",
    "\n",
    "# Check that the model state has been preserved\n",
    "new_predictions = new_model.predict(x_test)\n",
    "np.testing.assert_allclose(predictions, new_predictions, rtol=1e-6, atol=1e-6)\n",
    "\n",
    "# The optimizer state is preserved as well,\n",
    "# so you can resume training where you left off\n",
    "new_first_batch_loss = new_model.train_on_batch(x_train[:64], y_train[:64])\n",
    "assert first_batch_loss == new_first_batch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2_XaE5Oqv7Rh"
   },
   "source": [
    "You've reached the end of this guide! This covers everything you need to know about saving and serializing models with tf.keras in TensorFlow 2.0."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "saving_and_serializing.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
